{"cells":[{"cell_type":"markdown","metadata":{"id":"bpZZpp_9l6-U"},"source":["**preparing my colab environment**\n","\n","first I prepare my drive to be mounted on colab notebok"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15549,"status":"ok","timestamp":1642076538372,"user":{"displayName":"alireza samadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1rvUsWUWglw4bHdIjOXTa4XhrFtdw1wUpGtsY=s64","userId":"15397229150758724266"},"user_tz":-60},"id":"AGZjkjkwdYG2","outputId":"9dce9dc7-1a87-40fd-ec39-8a389672e434"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/MyDrive/Colab Notebooks/CVFOLDER/CVPROJECT\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd gdrive/MyDrive/Colab Notebooks/CVFOLDER/CVPROJECT\n","import sys\n","path_to_module = '/content/gdrive/MyDrive/Colab Notebooks/CVFOLDER/CVPROJECT/'\n","sys.path.append(path_to_module)"]},{"cell_type":"code","source":[""],"metadata":{"id":"S6ToytJKZKck"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SzUoztvImZW8"},"source":["then i import requured libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"muBKqa7dc_HE"},"outputs":[],"source":["import os\n","import pickle\n","import sys\n","import sys\n","import time\n","import cv2\n","# IMPORT LOCAL IMPLEMENTATION OF TORCHVISION'S DETECTION LIBRARY\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","import torchvision\n","import utils\n","from PIL import Image as PILImage\n","# IMPORT LOCAL IMPLEMENTATION OF TORCHVISION'S DETECTION LIBRARY\n","# Faster R-CNN interface\n","import models.mask_net as mask_net\n","from models.mask_net.faster_rcnn import FastRCNNPredictor, TwoMLPHead\n","from models.mask_net.rpn import AnchorGenerator\n","from torch.utils import data\n","from torchvision import transforms\n","import datasets.dataset_classifier as dataset\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v1DRyqfqjkKW"},"outputs":[],"source":["# main method\n","def main(config):\n","    torch.manual_seed(time.time())\n","    start_time = time.time()\n","    start_epoch = config[\"start_epoch\"]\n","    model_name = config[\"model_name\"]\n","    num_epochs = config[\"num_epochs\"]   #def:  50\n","    save_dir = config[\"save_dir\"]   #dir for saving masked imgs\n","    train_data_dir = config[\"train_data_dir\"]\n","    val_data_dir = config[\"val_data_dir\"]\n","    batch_size = config[\"batch_size\"]\n","    save_every = config[\"save_every\"]\n","    lrate = config[\"lrate\"]\n","    rpn_nms = config[\"rpn_nms_th\"]\n","    roi_nms = config[\"roi_nms_th\"]\n","    backbone_name = config[\"backbone_name\"]\n","    truncation = config[\"truncation\"]\n","    roi_batch_size = config[\"roi_batch_size\"]\n","    n_c = config[\"num_classes\"]\n","    s_features = config[\"s_features\"]\n","    device = config[\"device\"]\n","    if device == 'cuda' and torch.cuda.is_available():\n","        device = torch.device('cuda')\n","    else:\n","        device = torch.device('cpu')\n","    pretrained_classifier = config[\"pretrained_classification_model\"]\n","    pretrained_segment = config[\"pretrained_segmentation_model\"]\n","    if pretrained_classifier is not None and pretrained_segment is not None:\n","        print(\"Not clear which model to use, switching to the classifier\")\n","        pretrained_model = pretrained_classifier\n","    elif pretrained_classifier is not None and pretrained_segment is None:\n","        pretrained_model = pretrained_classifier\n","    else:\n","        pretrained_model = pretrained_segment\n","    print(device)\n","\n","##############################################################################################\n","    # DATASETS+DATALOADERS\n","    # parameters for the dataset\n","    # 512x512 is the recommended image size input\n","    dataset_covid_pars_train_cl = {'stage': 'train', 'data': train_data_dir, 'img_size': (512,512)}\n","    datapoint_covid_train_cl = dataset.COVID_CT_DATA(**dataset_covid_pars_train_cl)\n","    #\n","    dataset_covid_pars_eval_cl = {'stage': 'eval', 'data': val_data_dir, 'img_size': (512,512)}\n","    datapoint_covid_eval_cl = dataset.COVID_CT_DATA(**dataset_covid_pars_eval_cl)\n","    #\n","    dataloader_covid_pars_train_cl = {'shuffle': True, 'batch_size': batch_size}\n","    dataloader_covid_train_cl = data.DataLoader(datapoint_covid_train_cl, **dataloader_covid_pars_train_cl)\n","    #\n","    dataloader_covid_pars_eval_cl = {'shuffle': True, 'batch_size': batch_size}\n","    dataloader_covid_eval_cl = data.DataLoader(datapoint_covid_eval_cl, **dataloader_covid_pars_eval_cl)\n","    #\n","    ckpt = torch.load(pretrained_model, map_location=device)\n","    #\n","    covid_mask_net_args = {'num_classes': None, 'min_size': 512, 'max_size': 1024, 'box_detections_per_img': roi_batch_size, 'box_nms_thresh': roi_nms, 'box_score_thresh': -0.01, 'rpn_nms_thresh': rpn_nms}\n","\n","    # copy the anchor generator parameters, create a new one to avoid implementations' clash\n","    sizes = ckpt['anchor_generator'].sizes\n","    aspect_ratios = ckpt['anchor_generator'].aspect_ratios\n","    anchor_generator = AnchorGenerator(sizes, aspect_ratios)\n","    # out_channels:256, FPN\n","    # num_classes:3 (1+2)\n","    box_head = TwoMLPHead(in_channels=256*7*7, representation_size=128)\n","    box_predictor = FastRCNNPredictor(in_channels=128, num_classes=n_c)\n","    \n","    covid_mask_net_args['rpn_anchor_generator'] = anchor_generator\n","    covid_mask_net_args['box_predictor'] = box_predictor\n","    covid_mask_net_args['box_head'] = box_head\n","    covid_mask_net_args['s_representation_size'] = s_features\n","    # Instantiate the model\n","    covid_mask_net_model = mask_net.fasterrcnn_resnet_fpn(backbone_name, truncation, **covid_mask_net_args)\n","    # which parameters to train?\n","    trained_pars = []\n","    # if the weights are loaded from the segmentation model:\n","    if pretrained_classifier is None:\n","        for _n, _par in covid_mask_net_model.state_dict().items():\n","            if _n in ckpt['model_weights']:\n","                print('Loading parameter', _n)\n","                _par.copy_(ckpt['model_weights'][_n])\n","    # if the weights are loaded from the classification model\n","    else:\n","        covid_mask_net_model.load_state_dict(ckpt['model_weights'])\n","        if 'epoch' in ckpt.keys():\n","            start_epoch = int(ckpt['epoch']) + 1\n","        if 'model_name' in ckpt.keys():\n","            model_name = str(ckpt['model_name'])\n","\n","    # Evaluation mode, no labels!\n","    covid_mask_net_model.eval()\n","    # set the model to training mode without triggering the 'training' mode of Mask R-CNN\n","    # set up the optimizer\n","    utils.switch_model_on(covid_mask_net_model, ckpt, trained_pars)\n","    utils.set_to_train_mode(covid_mask_net_model)\n","    covid_mask_net_model = covid_mask_net_model.to(device)\n","    total_trained_pars = sum([x.numel() for x in trained_pars])\n","    print(\"Total trained pars {0:d}\".format(total_trained_pars))\n","    optimizer_pars = {'lr': lrate, 'weight_decay': 1e-3}\n","    optimizer = torch.optim.Adam(trained_pars, **optimizer_pars)\n","    if pretrained_classifier is not None and 'optimizer_state' in ckpt.keys():\n","        optimizer.load_state_dict(ckpt['optimizer_state'])\n","\n","    if start_epoch>0:\n","       num_epochs += start_epoch\n","    print(\"Start training, epoch = {:d}\".format(start_epoch))\n","    for e in range(start_epoch, num_epochs):\n","        train_loss_epoch = step(\"train\", e, dataloader_covid_train_cl, optimizer, device, covid_mask_net_model, save_every, lrate, model_name, None, None)\n","        eval_loss_epoch = step(\"eval\", e, dataloader_covid_eval_cl, optimizer, device, covid_mask_net_model,save_every, lrate, model_name, anchor_generator, save_dir)\n","        print(\"Epoch {0:d}: train loss = {1:.3f}, validation loss = {2:.3f}\".format(e, train_loss_epoch, eval_loss_epoch))\n","    end_time = time.time()\n","    print(\"Training took {0:.1f} seconds\".format(end_time - start_time))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qm-kV1N9dVVD"},"outputs":[],"source":["def step(stage, e, dataloader, optimizer, device, model, save_every, lrate, model_name, anchors, save_dir):\n","    epoch_loss = 0\n","    for id, b in enumerate(tqdm(dataloader)):\n","        optimizer.zero_grad()\n","        X, y = b\n","        if device == torch.device('cuda'):\n","            X, y = X.to(device), y.to(device)\n","        # some batches are less than batch_size\n","        batch_s = X.size()[0]\n","        batch_scores = []\n","        # input all images in the batch into COVID-Mask-Net to get B scores\n","        for id in range(batch_s):\n","            image = [X[id]]  # remove the batch dimension\n","            predict_scores = model(image)\n","            batch_scores.append(predict_scores[0]['final_scores'])\n","        # batchify scores/image and compute binary cross-entropy loss\n","        batch_scores = torch.stack(batch_scores)\n","        batch_loss = F.binary_cross_entropy_with_logits(batch_scores, y)\n","        if stage == \"train\":\n","            batch_loss.backward()\n","            optimizer.step()\n","        else:\n","            pass\n","        epoch_loss += batch_loss.clone().detach().cpu().numpy()\n","    epoch_loss = epoch_loss / len(dataloader)\n","    if not (e+1) % save_every and stage == \"eval\":\n","        model.eval()\n","        state = {'epoch': str(e+1), 'model_weights': model.state_dict(),'optimizer_state': optimizer.state_dict(), 'lrate': lrate, 'anchor_generator': anchors,\n","                 'model_name': model_name}\n","        if model_name is None:\n","            torch.save(state, os.path.join(save_dir, \"covid_ct_mask_net_ckpt_\" + str(e+1) + \".pth\"))\n","        else:\n","            torch.save(state, os.path.join(save_dir, model_name + \"_ckpt_\" + str(e+1) + \".pth\"))\n","        utils.set_to_train_mode(model)\n","    \n","    return epoch_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZBXdarl4dXCb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642081266884,"user_tz":-60,"elapsed":4428819,"user":{"displayName":"alireza samadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1rvUsWUWglw4bHdIjOXTa4XhrFtdw1wUpGtsY=s64","userId":"15397229150758724266"}},"outputId":"77d4f25f-7ff6-4364-a10a-511f513c3e83"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torchvision.models.detection.anchor_utils.AnchorGenerator' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n"]},{"output_type":"stream","name":"stdout","text":["backbone.body.conv1.weight grads on\n","backbone.body.bn1.weight trainable pars\n","backbone.body.bn1.bias trainable pars\n","backbone.body.layer1.0.conv1.weight grads on\n","backbone.body.layer1.0.bn1.weight trainable pars\n","backbone.body.layer1.0.bn1.bias trainable pars\n","backbone.body.layer1.0.conv2.weight grads on\n","backbone.body.layer1.0.bn2.weight trainable pars\n","backbone.body.layer1.0.bn2.bias trainable pars\n","backbone.body.layer1.0.conv3.weight grads on\n","backbone.body.layer1.0.bn3.weight trainable pars\n","backbone.body.layer1.0.bn3.bias trainable pars\n","backbone.body.layer1.0.downsample.0.weight grads on\n","backbone.body.layer1.0.downsample.1.weight grads on\n","backbone.body.layer1.0.downsample.1.bias grads on\n","backbone.body.layer1.1.conv1.weight grads on\n","backbone.body.layer1.1.bn1.weight trainable pars\n","backbone.body.layer1.1.bn1.bias trainable pars\n","backbone.body.layer1.1.conv2.weight grads on\n","backbone.body.layer1.1.bn2.weight trainable pars\n","backbone.body.layer1.1.bn2.bias trainable pars\n","backbone.body.layer1.1.conv3.weight grads on\n","backbone.body.layer1.1.bn3.weight trainable pars\n","backbone.body.layer1.1.bn3.bias trainable pars\n","backbone.body.layer1.2.conv1.weight grads on\n","backbone.body.layer1.2.bn1.weight trainable pars\n","backbone.body.layer1.2.bn1.bias trainable pars\n","backbone.body.layer1.2.conv2.weight grads on\n","backbone.body.layer1.2.bn2.weight trainable pars\n","backbone.body.layer1.2.bn2.bias trainable pars\n","backbone.body.layer1.2.conv3.weight grads on\n","backbone.body.layer1.2.bn3.weight trainable pars\n","backbone.body.layer1.2.bn3.bias trainable pars\n","backbone.body.layer2.0.conv1.weight grads on\n","backbone.body.layer2.0.bn1.weight trainable pars\n","backbone.body.layer2.0.bn1.bias trainable pars\n","backbone.body.layer2.0.conv2.weight grads on\n","backbone.body.layer2.0.bn2.weight trainable pars\n","backbone.body.layer2.0.bn2.bias trainable pars\n","backbone.body.layer2.0.conv3.weight grads on\n","backbone.body.layer2.0.bn3.weight trainable pars\n","backbone.body.layer2.0.bn3.bias trainable pars\n","backbone.body.layer2.0.downsample.0.weight grads on\n","backbone.body.layer2.0.downsample.1.weight grads on\n","backbone.body.layer2.0.downsample.1.bias grads on\n","backbone.body.layer2.1.conv1.weight grads on\n","backbone.body.layer2.1.bn1.weight trainable pars\n","backbone.body.layer2.1.bn1.bias trainable pars\n","backbone.body.layer2.1.conv2.weight grads on\n","backbone.body.layer2.1.bn2.weight trainable pars\n","backbone.body.layer2.1.bn2.bias trainable pars\n","backbone.body.layer2.1.conv3.weight grads on\n","backbone.body.layer2.1.bn3.weight trainable pars\n","backbone.body.layer2.1.bn3.bias trainable pars\n","backbone.body.layer2.2.conv1.weight grads on\n","backbone.body.layer2.2.bn1.weight trainable pars\n","backbone.body.layer2.2.bn1.bias trainable pars\n","backbone.body.layer2.2.conv2.weight grads on\n","backbone.body.layer2.2.bn2.weight trainable pars\n","backbone.body.layer2.2.bn2.bias trainable pars\n","backbone.body.layer2.2.conv3.weight grads on\n","backbone.body.layer2.2.bn3.weight trainable pars\n","backbone.body.layer2.2.bn3.bias trainable pars\n","backbone.body.layer2.3.conv1.weight grads on\n","backbone.body.layer2.3.bn1.weight trainable pars\n","backbone.body.layer2.3.bn1.bias trainable pars\n","backbone.body.layer2.3.conv2.weight grads on\n","backbone.body.layer2.3.bn2.weight trainable pars\n","backbone.body.layer2.3.bn2.bias trainable pars\n","backbone.body.layer2.3.conv3.weight grads on\n","backbone.body.layer2.3.bn3.weight trainable pars\n","backbone.body.layer2.3.bn3.bias trainable pars\n","backbone.body.layer3.0.conv1.weight grads on\n","backbone.body.layer3.0.bn1.weight trainable pars\n","backbone.body.layer3.0.bn1.bias trainable pars\n","backbone.body.layer3.0.conv2.weight grads on\n","backbone.body.layer3.0.bn2.weight trainable pars\n","backbone.body.layer3.0.bn2.bias trainable pars\n","backbone.body.layer3.0.conv3.weight grads on\n","backbone.body.layer3.0.bn3.weight trainable pars\n","backbone.body.layer3.0.bn3.bias trainable pars\n","backbone.body.layer3.0.downsample.0.weight grads on\n","backbone.body.layer3.0.downsample.1.weight grads on\n","backbone.body.layer3.0.downsample.1.bias grads on\n","backbone.body.layer3.1.conv1.weight grads on\n","backbone.body.layer3.1.bn1.weight trainable pars\n","backbone.body.layer3.1.bn1.bias trainable pars\n","backbone.body.layer3.1.conv2.weight grads on\n","backbone.body.layer3.1.bn2.weight trainable pars\n","backbone.body.layer3.1.bn2.bias trainable pars\n","backbone.body.layer3.1.conv3.weight grads on\n","backbone.body.layer3.1.bn3.weight trainable pars\n","backbone.body.layer3.1.bn3.bias trainable pars\n","backbone.body.layer3.2.conv1.weight grads on\n","backbone.body.layer3.2.bn1.weight trainable pars\n","backbone.body.layer3.2.bn1.bias trainable pars\n","backbone.body.layer3.2.conv2.weight grads on\n","backbone.body.layer3.2.bn2.weight trainable pars\n","backbone.body.layer3.2.bn2.bias trainable pars\n","backbone.body.layer3.2.conv3.weight grads on\n","backbone.body.layer3.2.bn3.weight trainable pars\n","backbone.body.layer3.2.bn3.bias trainable pars\n","backbone.body.layer3.3.conv1.weight grads on\n","backbone.body.layer3.3.bn1.weight trainable pars\n","backbone.body.layer3.3.bn1.bias trainable pars\n","backbone.body.layer3.3.conv2.weight grads on\n","backbone.body.layer3.3.bn2.weight trainable pars\n","backbone.body.layer3.3.bn2.bias trainable pars\n","backbone.body.layer3.3.conv3.weight grads on\n","backbone.body.layer3.3.bn3.weight trainable pars\n","backbone.body.layer3.3.bn3.bias trainable pars\n","backbone.body.layer3.4.conv1.weight grads on\n","backbone.body.layer3.4.bn1.weight trainable pars\n","backbone.body.layer3.4.bn1.bias trainable pars\n","backbone.body.layer3.4.conv2.weight grads on\n","backbone.body.layer3.4.bn2.weight trainable pars\n","backbone.body.layer3.4.bn2.bias trainable pars\n","backbone.body.layer3.4.conv3.weight grads on\n","backbone.body.layer3.4.bn3.weight trainable pars\n","backbone.body.layer3.4.bn3.bias trainable pars\n","backbone.body.layer3.5.conv1.weight grads on\n","backbone.body.layer3.5.bn1.weight trainable pars\n","backbone.body.layer3.5.bn1.bias trainable pars\n","backbone.body.layer3.5.conv2.weight grads on\n","backbone.body.layer3.5.bn2.weight trainable pars\n","backbone.body.layer3.5.bn2.bias trainable pars\n","backbone.body.layer3.5.conv3.weight grads on\n","backbone.body.layer3.5.bn3.weight trainable pars\n","backbone.body.layer3.5.bn3.bias trainable pars\n","backbone.body.layer4.0.conv1.weight grads on\n","backbone.body.layer4.0.bn1.weight trainable pars\n","backbone.body.layer4.0.bn1.bias trainable pars\n","backbone.body.layer4.0.conv2.weight grads on\n","backbone.body.layer4.0.bn2.weight trainable pars\n","backbone.body.layer4.0.bn2.bias trainable pars\n","backbone.body.layer4.0.conv3.weight grads on\n","backbone.body.layer4.0.bn3.weight trainable pars\n","backbone.body.layer4.0.bn3.bias trainable pars\n","backbone.body.layer4.0.downsample.0.weight grads on\n","backbone.body.layer4.0.downsample.1.weight grads on\n","backbone.body.layer4.0.downsample.1.bias grads on\n","backbone.body.layer4.1.conv1.weight grads on\n","backbone.body.layer4.1.bn1.weight trainable pars\n","backbone.body.layer4.1.bn1.bias trainable pars\n","backbone.body.layer4.1.conv2.weight grads on\n","backbone.body.layer4.1.bn2.weight trainable pars\n","backbone.body.layer4.1.bn2.bias trainable pars\n","backbone.body.layer4.1.conv3.weight grads on\n","backbone.body.layer4.1.bn3.weight trainable pars\n","backbone.body.layer4.1.bn3.bias trainable pars\n","backbone.body.layer4.2.conv1.weight grads on\n","backbone.body.layer4.2.bn1.weight trainable pars\n","backbone.body.layer4.2.bn1.bias trainable pars\n","backbone.body.layer4.2.conv2.weight grads on\n","backbone.body.layer4.2.bn2.weight trainable pars\n","backbone.body.layer4.2.bn2.bias trainable pars\n","backbone.body.layer4.2.conv3.weight grads on\n","backbone.body.layer4.2.bn3.weight trainable pars\n","backbone.body.layer4.2.bn3.bias trainable pars\n","backbone.fpn.inner_blocks.0.weight grads on\n","backbone.fpn.inner_blocks.0.bias grads on\n","backbone.fpn.inner_blocks.1.weight grads on\n","backbone.fpn.inner_blocks.1.bias grads on\n","backbone.fpn.inner_blocks.2.weight grads on\n","backbone.fpn.inner_blocks.2.bias grads on\n","backbone.fpn.inner_blocks.3.weight grads on\n","backbone.fpn.inner_blocks.3.bias grads on\n","backbone.fpn.layer_blocks.0.weight grads on\n","backbone.fpn.layer_blocks.0.bias grads on\n","backbone.fpn.layer_blocks.1.weight grads on\n","backbone.fpn.layer_blocks.1.bias grads on\n","backbone.fpn.layer_blocks.2.weight grads on\n","backbone.fpn.layer_blocks.2.bias grads on\n","backbone.fpn.layer_blocks.3.weight grads on\n","backbone.fpn.layer_blocks.3.bias grads on\n","rpn.head.conv.weight grads on\n","rpn.head.conv.bias grads on\n","rpn.head.cls_logits.weight grads on\n","rpn.head.cls_logits.bias grads on\n","rpn.head.bbox_pred.weight grads on\n","rpn.head.bbox_pred.bias grads on\n","roi_heads.box_head.fc6.weight grads on\n","roi_heads.box_head.fc6.bias grads on\n","roi_heads.box_head.fc7.weight grads on\n","roi_heads.box_head.fc7.bias grads on\n","roi_heads.box_predictor.cls_score.weight grads on\n","roi_heads.box_predictor.cls_score.bias grads on\n","roi_heads.box_predictor.bbox_pred.weight grads on\n","roi_heads.box_predictor.bbox_pred.bias grads on\n","s2new.fc_scores.weight trainable pars\n","s2new.fc_scores.bias trainable pars\n","s2new.fc_scores_2.weight trainable pars\n","s2new.fc_scores_2.bias trainable pars\n","s2new.fc_scores_img.weight trainable pars\n","s2new.fc_scores_img.bias trainable pars\n","Setting s2new to training mode\n","Total trained pars 2409859\n","Start training, epoch = 51\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/3000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","100%|██████████| 3000/3000 [06:54<00:00,  7.23it/s]\n","100%|██████████| 1007/1007 [01:04<00:00, 15.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Setting s2new to training mode\n","Epoch 51: train loss = 0.030, validation loss = 0.129\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3000/3000 [06:18<00:00,  7.93it/s]\n","100%|██████████| 1007/1007 [00:55<00:00, 18.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52: train loss = 0.030, validation loss = 0.136\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3000/3000 [06:18<00:00,  7.93it/s]\n","100%|██████████| 1007/1007 [00:55<00:00, 18.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Setting s2new to training mode\n","Epoch 53: train loss = 0.024, validation loss = 0.129\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3000/3000 [06:19<00:00,  7.91it/s]\n","100%|██████████| 1007/1007 [00:55<00:00, 18.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54: train loss = 0.030, validation loss = 0.141\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3000/3000 [06:17<00:00,  7.94it/s]\n","100%|██████████| 1007/1007 [00:54<00:00, 18.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Setting s2new to training mode\n","Epoch 55: train loss = 0.020, validation loss = 0.153\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3000/3000 [06:17<00:00,  7.94it/s]\n","100%|██████████| 1007/1007 [00:55<00:00, 18.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56: train loss = 0.017, validation loss = 0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3000/3000 [06:19<00:00,  7.90it/s]\n","100%|██████████| 1007/1007 [00:56<00:00, 17.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Setting s2new to training mode\n","Epoch 57: train loss = 0.013, validation loss = 0.119\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3000/3000 [06:21<00:00,  7.86it/s]\n","100%|██████████| 1007/1007 [00:56<00:00, 17.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58: train loss = 0.012, validation loss = 0.135\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3000/3000 [06:21<00:00,  7.86it/s]\n","100%|██████████| 1007/1007 [00:56<00:00, 17.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Setting s2new to training mode\n","Epoch 59: train loss = 0.013, validation loss = 0.131\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3000/3000 [06:20<00:00,  7.88it/s]\n","100%|██████████| 1007/1007 [00:56<00:00, 17.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60: train loss = 0.008, validation loss = 0.166\n","Training took 4428.5 seconds\n"]}],"source":["# run the training\n","if __name__ == '__main__':\n","    config_dict = {\n","        \"start_epoch\": 1,\n","        \"pretrained_classification_model\": \"Classification_folder/pretrained_model_for_image_classification/classification_model_both_classes.pth\",\n","        \"pretrained_segmentation_model\": None,\n","        \"model_name\": \"Alireza_model_\",\n","        \"num_epochs\": 10,\n","        \"save_dir\": \"Classification_folder/saved_models__checkpoints__/\",  # dir for saving masked imgs\n","        \"train_data_dir\": \"Classification_folder/covid_data/cncb/train/\",\n","        \"val_data_dir\": \"Classification_folder/covid_data/cncb/validation/\",\n","        \"batch_size\": 1,\n","        \"device\": \"cuda\",\n","        \"save_every\": 2,\n","        \"lrate\": 1e-5,\n","        \"roi_nms_th\": 0.75,\n","        \"roi_batch_size\": 256,\n","        \"rpn_nms_th\": 0.75,\n","        \"backbone_name\": \"resnet50\",\n","        \"truncation\": '0',\n","        \"num_classes\": 3,\n","        \"s_features\": 1024\n","    }\n","    main(config_dict)"]}],"metadata":{"colab":{"name":"2_train_classifier.ipynb","provenance":[],"authorship_tag":"ABX9TyPRD3x3jweZPdv480E2nvel"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}